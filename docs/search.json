[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring cognitive diversity in a sample of children from Unsatisfied Basic Needs homes",
    "section": "",
    "text": "This public document accompanies the article “Exploring cognitive diversity in a sample of children from Unsatisfied Basic Needs homes” published in (update when published). It shows the main and supplementary analyses along with its corresponding code."
  },
  {
    "objectID": "pre_cluster_analysis.html#data",
    "href": "pre_cluster_analysis.html#data",
    "title": "Pre-clustering analyses",
    "section": "0. Data",
    "text": "0. Data\n\n\nCode\n# Cargando datos\ndatos = read.csv(\"../data/datos_normalizados.csv\")\ndatos.reducidos = read.csv(\"../data/datos_reducidos.csv\")\nsubject.info &lt;- read.csv(\"../data/subject_information_PICT2014.csv\")",
    "crumbs": [
      "Index",
      "Supplementary materials",
      "Pre-clustering analyses"
    ]
  },
  {
    "objectID": "pre_cluster_analysis.html#sample-information",
    "href": "pre_cluster_analysis.html#sample-information",
    "title": "Pre-clustering analyses",
    "section": "0.0. Sample information",
    "text": "0.0. Sample information\n\n\nCode\n  datos.reducidos %&gt;% \n    left_join(subject.info, by = \"username\") %&gt;% \n    summarise(n = as.character(n()),\n              girls = as.character(sum(Sex == \"fem\", na.rm = TRUE)),\n              Age = paste(mean(Age, na.rm = TRUE),\n                          \" (\",\n                          round(\n                            sd(\n                              Age,\n                              na.rm = TRUE),\n                            digits = 3),\n                          \")\", sep = \"\")\n              ) %&gt;% \n    pivot_longer(everything()) %&gt;%\n    flextable() %&gt;% \n    # custom_flextable(\"\")%&gt;%\n    set_header_labels(name = \"Sample information\", value = \"\") %&gt;%  # Remove column names\n \n    autofit() \n\n\nSample informationn105girls50Age5.328 (0.329)",
    "crumbs": [
      "Index",
      "Supplementary materials",
      "Pre-clustering analyses"
    ]
  },
  {
    "objectID": "pre_cluster_analysis.html#optimal-number-of-k",
    "href": "pre_cluster_analysis.html#optimal-number-of-k",
    "title": "Pre-clustering analyses",
    "section": "1. Optimal number of k",
    "text": "1. Optimal number of k\n\n\nCode\n# Método del codo\n\nfviz_nbclust(datos, kmeans, method = \"wss\") +\n  labs(subtitle = \"Elbow method\")\n\n\n\n\n\n\n\n\n\nCode\n# Método silueta\n\nfviz_nbclust(datos, kmeans, method = \"silhouette\")+\n  labs(subtitle = \"Silhouette method\")",
    "crumbs": [
      "Index",
      "Supplementary materials",
      "Pre-clustering analyses"
    ]
  },
  {
    "objectID": "pre_cluster_analysis.html#algorithm-diagnostics",
    "href": "pre_cluster_analysis.html#algorithm-diagnostics",
    "title": "Pre-clustering analyses",
    "section": "2. Algorithm diagnostics",
    "text": "2. Algorithm diagnostics\n\n2.1. Kmeans\n\n2.1.1. Kmeans with Euclidean distances\n\n\n\nCode\nBC_kmeans &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"euclidean\",\n    algorithms = c(\"km\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_kmeans, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  55  43  32  23\n2        2  50  43  28  16\n3        3  NA  19  24  18\n4        4  NA  NA  21  25\n5        5  NA  NA  NA  23\n\n\n\n\n\n\n2.2. PAM\n\n2.2.1. PAM with Euclidean distances\n\n\n\nCode\nBC_pam_euclidean &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"euclidean\",\n    algorithms = c(\"pam\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_pam_euclidean, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  59  40  42  44\n2        2  46  40  28  24\n3        3  NA  25  19   7\n4        4  NA  NA  16  11\n5        5  NA  NA  NA  19\n\n\n\n\n\n2.2.2. PAM with Manhattan distances\n\n\n\nCode\nBC_pam_manhattan &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"manhattan\",\n    algorithms = c(\"pam\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_pam_manhattan, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  74  52  46  41\n2        2  31  31  25  27\n3        3  NA  22  10  11\n4        4  NA  NA  24   9\n5        5  NA  NA  NA  17\n\n\n\n\n\n\n2.3. Diana\n\n2.3.1. Diana with euclidean distances\n\n\n\nCode\nBC_diana_euclidean &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"euclidean\",\n    algorithms = c(\"diana\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_diana_euclidean, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  78  74  71  51\n2        2  27  24  15  14\n3        3  NA   7  14  12\n4        4  NA  NA   5  22\n5        5  NA  NA  NA   6\n\n\n\n\n\n2.2.2. Diana with manhattan distances\n\n\n\nCode\nBC_diana_manhattan &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"manhattan\",\n    algorithms = c(\"diana\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_diana_manhattan, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  72  63  59  51\n2        2  33  24  13  12\n3        3  NA  18  26  10\n4        4  NA  NA   7  20\n5        5  NA  NA  NA  12\n\n\n\n\n\n\n2.4. Hierarchical\n\n2.4.1. Hierarchical with euclidean distances and average agglomeration method\n\n\n\nCode\nBC_hc_euclidean_average &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"euclidean\",\n    hc.method = \"average\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_euclidean_average, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1 104 102  96  91\n2        2   1   1   5   9\n3        3  NA   2   1   3\n4        4  NA  NA   3   1\n5        5  NA  NA  NA   1\n\n\n\n\n\n2.4.2. Hierarchical with manhattan distances and average agglomeration method\n\n\n\nCode\nBC_hc_manhattan_average &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"manhattan\",\n    hc.method = \"average\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_manhattan_average, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1 102  96  90  88\n2        2   3   7  10   7\n3        3  NA   2   4   4\n4        4  NA  NA   1   3\n5        5  NA  NA  NA   3\n\n\n\n\n\n2.4.3. Hierarchical with euclidean distances and ward.D agglomeration method\n\n\n\nCode\nBC_hc_euclidean_ward &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"euclidean\",\n    hc.method = \"ward.D\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_euclidean_ward, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  85  63  62  56\n2        2  20  25  22  17\n3        3  NA  17  14  16\n4        4  NA  NA   7   4\n5        5  NA  NA  NA  12\n\n\n\n\n\n2.4.4. Hierarchical with manhattan distances and ward.D agglomeration method\n\n\n\nCode\nBC_hc_euclidean_ward &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"manhattan\",\n    hc.method = \"ward.D\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_euclidean_ward, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  96  60  51  49\n2        2   9  24  33   9\n3        3  NA  21   6  18\n4        4  NA  NA  15   3\n5        5  NA  NA  NA  26\n\n\n\n\n\n2.4.5. Hierarchical with euclidean distances and ward.D2 agglomeration method\n\n\n\nCode\nBC_hc_euclidean_ward2 &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"euclidean\",\n    hc.method = \"ward.D2\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_euclidean_ward2, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  85  72  59  56\n2        2  20  18  24  15\n3        3  NA  15   5  14\n4        4  NA  NA  17   6\n5        5  NA  NA  NA  14\n\n\n\n\n\n2.4.6. Hierarchical with manhattan distances and ward.D2 agglomeration method\n\n\n\nCode\nBC_hc_euclidean_ward2 &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"manhattan\",\n    hc.method = \"ward.D2\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_euclidean_ward2, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  83  66  42  40\n2        2  22  32  35  35\n3        3  NA   7  14   9\n4        4  NA  NA  14   4\n5        5  NA  NA  NA  17\n\n\n\n\n\n2.4.7. Hierarchical with euclidean distances and complete agglomeration method\n\n\n\nCode\nBC_hc_euclidean_complete &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"euclidean\",\n    hc.method = \"complete\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_euclidean_complete, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  91  87  81  81\n2        2  14  13  11   6\n3        3  NA   5   9   3\n4        4  NA  NA   4  12\n5        5  NA  NA  NA   3\n\n\n\n\n\n2.4.8. Hierarchical with manhattan distances and complete agglomeration method\n\n\n\nCode\nBC_hc_euclidean_complete &lt;- consensus_cluster(datos,\n    nk = 2:5, # Number of clusters for BCs\n    p.item = 0.8,  # Randomly selected 80% of the original data\n    reps = 100, # Generate 100 BCs,\n    seed.data = 999,\n    distance = \"manhattan\",\n    hc.method = \"complete\",\n    algorithms = c(\"hc\") # BC algorithms we use k-means\n)\n\ninternal_ensemble_validity(BC_hc_euclidean_complete, 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na flextable object.\ncol_keys: `Clusters`, `k=2`, `k=3`, `k=4`, `k=5` \nheader has 1 row(s) \nbody has 5 row(s) \noriginal dataset sample: \n  Clusters k=2 k=3 k=4 k=5\n1        1  88  81  68  40\n2        2  17  19  19  40\n3        3  NA   5  10   9\n4        4  NA  NA   8  11\n5        5  NA  NA  NA   5\n\n\n\n:::",
    "crumbs": [
      "Index",
      "Supplementary materials",
      "Pre-clustering analyses"
    ]
  },
  {
    "objectID": "ensemble_clustering_results.html#table-1.-descriptive-and-inferential-analyses-for-clustering-result",
    "href": "ensemble_clustering_results.html#table-1.-descriptive-and-inferential-analyses-for-clustering-result",
    "title": "Main Analyses",
    "section": "2.1.Table 1. Descriptive and inferential analyses for clustering result",
    "text": "2.1.Table 1. Descriptive and inferential analyses for clustering result\n\n\nCode\n# Transform to long format\n\ndatos.long.z = datos %&gt;%\n  pivot_longer(!Clusters,names_to = \"Feature\") %&gt;% \n  mutate(Tipo = ifelse(grepl(\"rt\", Feature), \"Time\", \"Accuracy\")) %&gt;% \n  feature_rename() %&gt;% \n  arrange(factor(Feature, levels = feature_order)) \n\n\ndatos.long = datos.reducidos %&gt;%\n  select(-username) %&gt;% \n  pivot_longer(!Clusters,names_to = \"Feature\") %&gt;% \n  mutate(Tipo = ifelse(grepl(\"rt\", Feature), \"Time\", \"Accuracy\")) %&gt;% \n  feature_rename() %&gt;% \n  arrange(factor(Feature, levels = feature_order)) \n\n\n# Mean and SE values\n\ndatos.summarised.z = datos.long.z %&gt;%\n  group_by(Tipo, Feature, Clusters) %&gt;% \n  summarise(Mean = mean(value),\n            # SD = sd(value),\n            SE = sqrt(sum((value-mean(value))^2/(length(value)-1)))/sqrt(length(value))) %&gt;% \n  ungroup()\n\ndatos.summarised = datos.long %&gt;%\n  group_by(Tipo, Feature, Clusters) %&gt;% \n  summarise(n = n(),\n            Mean = mean(value),\n            # SD = sd(value),\n            SE = sqrt(sum((value-mean(value))^2/(length(value)-1)))/sqrt(length(value))\n            ) %&gt;% \n  ungroup()\n\n# Inferential analysis\n\ndatos.kruskal.z = datos.long.z %&gt;%\n  group_by(Feature) %&gt;% \n  nest() %&gt;% \n  mutate(modelos = map(data ,~kruskal.test(value ~ Clusters, data = .)),\n         summary = map(modelos, broom::tidy),) %&gt;% \n  unnest(summary) %&gt;% \n  mutate(Significance = case_when(\n    p.value &lt; .001 ~ \"***\",\n    p.value &gt;= .001 & p.value &lt; .01  ~ \"**\",\n    p.value &gt;= .01 & p.value &lt; .05 ~ \"*\",\n    p.value &gt;= .05 ~ \"\"\n  )) %&gt;% \n  select(-data,-modelos, -parameter, -method) \n\n\n\n# Plot data\n\ndatos.plot = datos.summarised.z %&gt;% \n  left_join(datos.kruskal.z, by = c(\"Feature\")) %&gt;% \n  arrange(factor(Feature, levels = feature_order)) \n\n# Formatted table\n  \n\n# Tidyverse pipeline\n(Table1 &lt;- datos.summarised %&gt;%\n  left_join(datos.kruskal.z, by = c(\"Feature\")) %&gt;% \n  arrange(factor(Feature, levels = feature_order)) %&gt;% \n  mutate(Task = gsub(\"_.*\", \"\", Feature)) %&gt;%  # Extract task name\n  select(-\"Tipo\", -\"Significance\") %&gt;%\n  select(Task, everything()) %&gt;%\n  rename(Statistic = \"statistic\") %&gt;% \n\n  mutate(Feature =str_remove(Feature, \"^[A-Z]+_\")) %&gt;%\n\n  custom_flextable(\"Table 1. Descriptive and inferential analyses for clustering result\") %&gt;% \n  merge_v(j = \"Feature\", target = c(\"Statistic\",\"p.value\")) %&gt;%\n  merge_v(j = 1:2) %&gt;%\n   # merge_v(j = c(\"Feature\", \"p.value\")) %&gt;%\n  valign(valign = \"top\") \n  )\n\n\nTaskFeatureClustersnMeanSEStatisticp.valueANTCorrect congruent trialsCluster 13934.1031.02542.018&lt;.001Cluster 22338.7391.226Cluster 34325.2091.199Correct incongruent trialsCluster 13919.2311.09146.193&lt;.001Cluster 22328.3481.555Cluster 34313.2790.736Omitted congruent trialsCluster 1398.6150.68238.591&lt;.001Cluster 2234.3040.611Cluster 34313.3261.052Omitted incongruent trialsCluster 13916.2310.74244.932&lt;.001Cluster 2237.4350.558Cluster 34319.4651.172RT congruent trialsCluster 1391,167.07717.28015.456&lt;.001Cluster 2231,022.10929.280Cluster 3431,158.02330.502RT incongruent trialsCluster 1391,285.33320.87718.506&lt;.001Cluster 2231,112.13037.953Cluster 3431,069.45340.119Alerting networkCluster 13995.64123.1980.0410.98Cluster 22397.17426.432Cluster 343107.60525.233Orienting networkCluster 139-6.26920.3280.2150.898Cluster 2231.67422.108Cluster 343-9.38423.247Executive networkCluster 139118.25617.20434.080&lt;.001Cluster 22390.02221.565Cluster 343-88.57026.702CORSICorrect trialsCluster 1395.9740.54922.934&lt;.001Cluster 22313.6091.447Cluster 3436.8370.626Execution time correct trialsCluster 13910.9780.29425.378&lt;.001Cluster 22313.4870.466Cluster 34313.3400.354Execution time incorrect trialsCluster 13914.8330.34522.803&lt;.001Cluster 22317.4220.680Cluster 34317.7920.475TOLCorrect trialsCluster 13910.8970.5791.8610.394Cluster 22311.2170.790Cluster 3439.6050.724Planning time correct trialsCluster 1395.6230.2504.8830.087Cluster 2235.2390.320Cluster 3436.1660.284KBITCorrect trialsCluster 13912.2820.44410.5580.005Cluster 22313.7390.686Cluster 34311.3020.431\n\n\nCode\nsave_table(Table1, \"../Tables/Table_1.docx\")",
    "crumbs": [
      "Index",
      "Main Analyses"
    ]
  },
  {
    "objectID": "ensemble_clustering_results.html#table-2.-pairwise-comparisons-for-clustering-result.",
    "href": "ensemble_clustering_results.html#table-2.-pairwise-comparisons-for-clustering-result.",
    "title": "Main Analyses",
    "section": "2.2.Table 2. Pairwise comparisons for clustering result.",
    "text": "2.2.Table 2. Pairwise comparisons for clustering result.\n\n\nCode\n(Table2 &lt;- datos.long.z %&gt;%\n  group_by(Feature) %&gt;%\n  nest() %&gt;%\n  mutate(\n    \n  # Pairwise mann-withney calculus\n    \n    modelo = map(data, ~ pairwise_wilcox_test(value ~ Clusters, data = .x, paired = FALSE) %&gt;%\n             select(group1, group2, statistic, p.adj)\n             ),\n    \n    # Storing p values\n    \n    p.value = map( \n      modelo, \n       ~ .x %&gt;%\n             mutate(contrasts = paste(group1, \"vs.\", group2, \"_p\")) %&gt;%\n             select(contrasts, p.adj) %&gt;%\n             pivot_wider(names_from = contrasts, values_from = p.adj)\n           ),\n    \n    # Storing U value\n    \n    U = map( \n      modelo, \n       ~ .x %&gt;%\n             mutate(contrasts = paste(group1, \"vs.\", group2, \"_U\")) %&gt;%\n             select(contrasts, statistic) %&gt;%\n             pivot_wider(names_from = contrasts, values_from = statistic)\n           ),\n    \n    # Calculate effect size (r) \n    \n    effsize = map(data, ~ wilcox_effsize(value ~ Clusters, data = .x, paired = FALSE) %&gt;%\n             select(group1, group2, effsize, n1, n2)\n             ),\n    \n     r.value = map(\n      effsize,\n       ~ .x %&gt;%\n        mutate(contrasts = paste(group1, \"vs.\", group2, \"_r\")) %&gt;%\n        select(contrasts, effsize) %&gt;%\n        pivot_wider(names_from = contrasts, values_from = effsize)\n      ),\n    \n    # Storing z score\n    \n    z.value = map(\n      effsize,\n      ~ .x %&gt;% \n        mutate(contrasts = paste(group1, \"vs.\", group2, \"_z\")) %&gt;%\n        mutate(z.value = effsize * sqrt(n1 + n2)) %&gt;% \n        select(contrasts, z.value) %&gt;%\n        pivot_wider(names_from = contrasts, values_from = z.value)\n      ),\n    \n    ) %&gt;% \n  \n  select(Feature, z.value, p.value, r.value) %&gt;%\n  \n  mutate(Task = gsub(\"_.*\", \"\", Feature)) %&gt;%  # Extract task name\n    select(Task, everything()) %&gt;%\n\n  mutate(Feature =str_remove(Feature, \"^[A-Z]+_\")) %&gt;%\n  unnest(z.value, p.value, r.value) %&gt;% \n  select(Task, Feature, \n         `Cluster 1 vs. Cluster 2 _z`, `Cluster 1 vs. Cluster 2 _p`, `Cluster 1 vs. Cluster 2 _r`,\n         `Cluster 1 vs. Cluster 3 _z`, `Cluster 1 vs. Cluster 3 _p`, `Cluster 1 vs. Cluster 3 _r`,\n         `Cluster 2 vs. Cluster 3 _z`, `Cluster 2 vs. Cluster 3 _p`, `Cluster 2 vs. Cluster 3 _r`) %&gt;% \n  \n  # Flextable implementation with bold and other format stuff\n  \n  custom_flextable(\"Pairwise comparisons for clustering result\") %&gt;%\n  bold(j = 3:5,~ `Cluster 1 vs. Cluster 2 _p` &lt; .05) %&gt;%\n  bold(j = 6:8,~ `Cluster 1 vs. Cluster 3 _p` &lt; .05)%&gt;%\n  bold(j = 9:11,~ `Cluster 2 vs. Cluster 3 _p` &lt; .05) %&gt;%\n  mk_par(j = 4,i = ~`Cluster 1 vs. Cluster 2 _p` &lt; .001, value = as_paragraph(\"&lt;.001\")) %&gt;%\n  mk_par(j = 7,i = ~`Cluster 1 vs. Cluster 3 _p` &lt; .001, value = as_paragraph(\"&lt;.001\")) %&gt;%\n  mk_par(j = 10,i = ~`Cluster 2 vs. Cluster 3 _p` &lt; .001, value = as_paragraph(\"&lt;.001\")) %&gt;%\n  \n  separate_header(split = \"_\") %&gt;% \n  merge_v(j = 1:2) %&gt;% \n  valign(valign = \"top\") %&gt;% \n   autofit()\n)\n\n\nTaskFeatureCluster 1 vs. Cluster 2 Cluster 1 vs. Cluster 3 Cluster 2 vs. Cluster 3 zprzprzprANTCorrect congruent trials2.8630.0040.3644.815&lt;.0010.5325.558&lt;.0010.684Correct incongruent trials4.058&lt;.0010.5153.948&lt;.0010.4366.240&lt;.0010.768Omitted congruent trials4.155&lt;.0010.5283.4170.0010.3775.594&lt;.0010.689Omitted incongruent trials6.184&lt;.0010.7851.8460.0660.2045.724&lt;.0010.705RT congruent trials3.840&lt;.0010.4880.4130.6830.0463.2770.0020.403RT incongruent trials3.811&lt;.0010.4843.5890.0010.3960.7870.4350.097Alerting network0.0071.0000.0010.1721.0000.0190.1681.0000.021Orienting network0.4441.0000.0560.1721.0000.0190.3431.0000.042Executive network1.2020.2320.1535.358&lt;.0010.5924.152&lt;.0010.511CORSICorrect trials4.633&lt;.0010.5880.6420.5240.0713.942&lt;.0010.485Execution time correct trials3.985&lt;.0010.5064.489&lt;.0010.4960.5320.6020.065Execution time incorrect trials3.2570.0020.4144.554&lt;.0010.5030.6390.5300.079TOLCorrect trials0.5350.7120.0680.9280.7120.1021.2700.6210.156Planning time correct trials1.1150.2960.1421.4530.2960.1601.9980.1370.246KBITCorrect trials2.1140.0700.2681.4730.1420.1633.1370.0050.386\n\n\nCode\nsave_table(Table2, \"../Tables/Table_2.docx\")",
    "crumbs": [
      "Index",
      "Main Analyses"
    ]
  },
  {
    "objectID": "ensemble_clustering_results.html#figure-1.-feature-comparisons-between-subjects",
    "href": "ensemble_clustering_results.html#figure-1.-feature-comparisons-between-subjects",
    "title": "Main Analyses",
    "section": "2.3.Figure 1. Feature comparisons between subjects",
    "text": "2.3.Figure 1. Feature comparisons between subjects\n\n\nCode\nplot.caracteristicas = function(df){\n  \n  df %&gt;% \n    ggplot(aes(x = Feature, \n               y = Mean, \n               color = factor(Clusters),\n               group = factor(Clusters),\n               label = Significance))+\n      geom_hline(yintercept =  0, linetype = \"dashed\", alpha = 0.6)+\n      geom_point(size = 4) +\n      geom_line(linewidth = 1.5, alpha = 0.5)+\n      geom_errorbar(aes(ymin = Mean - SE,\n                        ymax = Mean + SE), \n                    alpha = 0.8)+\n      geom_text(aes(y = 1.5), color = \"black\")+\n\n      coord_flip(ylim = c(-1.5,1.5))+\n      theme_minimal(base_size = 15) +\n        labs(colour = \"Clusters\")+\n        theme(\n          # legend.position = c(0.5, 0.5),  # Position legend at bottom-left\n          legend.justification = c(0.7, 0),  # Align legend to bottom-left\n          axis.title.y = element_blank()  # Remove y-axis title\n        )\n}\n\n\nplot.des = datos.plot %&gt;% \n  filter(Tipo == \"Accuracy\") %&gt;% \n  mutate(Feature = str_replace(Feature, \"_\", \" \")) %&gt;% \n  mutate(Feature = factor(Feature, levels =  c(\"ANT Correct congruent trials\",\n                                               \"ANT Correct incongruent trials\",\n                                               \"ANT Omitted congruent trials\",\n                                               \"ANT Omitted incongruent trials\",\n                                               \"CORSI Correct trials\",\n                                               \"TOL Correct trials\",          \n                                               \"KBIT Correct trials\")\n                          )\n         )%&gt;% \n  plot.caracteristicas()\n\n# plot.des\n\n\nplot.RT = datos.plot %&gt;% \n  filter(Tipo == \"Time\") %&gt;% \n  mutate(Feature = str_replace(Feature, \"_\", \" \")) %&gt;%\n  mutate(Feature = factor(Feature, levels =  c(\"ANT RT congruent trials\",\n                                               \"ANT RT incongruent trials\",\n                                               \n                                               \"ANT Executive network\",\n                                               \"ANT Alerting network\",\n                                               \n                                               \"ANT Orienting network\",\n                                               \n\n                                               \"CORSI Execution time correct trials\",\n                                               \"CORSI Execution time incorrect trials\",\n                                               \"TOL Planning time correct trials\",\n                                               \"TOL Planning time incorrect trials\"\n                                               )\n                          )\n         )%&gt;%\n\n  plot.caracteristicas()\n  \n# plot.RT\n\n\n(Figure1 = ggarrange(plotlist = list(plot.des + rremove(\"x.title\")+ rremove(\"x.text\"),\n                          plot.RT),\n          common.legend = T, \n          legend = \"bottom\",\n          labels = c(\"Accuracy\", \"Time\"),\n          hjust = 0,\n          vjust = .5,\n          ncol = 1,\n          heights = c(.7,1))+\n  \n  theme(plot.margin = margin(0.5,0,0,0.5, \"cm\")))\n\n\n\n\n\n\n\n\n\nCode\nFigure1%&gt;%\n  ggexport(filename = \"../Figures/Figure1.png\", width = 720, height = 720)",
    "crumbs": [
      "Index",
      "Main Analyses"
    ]
  },
  {
    "objectID": "ensemble_clustering_results.html#table-s1.-comparison-of-sex-between-clusters",
    "href": "ensemble_clustering_results.html#table-s1.-comparison-of-sex-between-clusters",
    "title": "Main Analyses",
    "section": "3.1. Table S1. Comparison of Sex between clusters",
    "text": "3.1. Table S1. Comparison of Sex between clusters\n\n\nCode\nvars = c(\"Sex\")\n\n\nsubject_info %&gt;%\n  summarise(across(all_of(vars), ~ list(fisher.test(table(Clusters, .x),\n                                                    simulate.p.value = T, B = 100000))))%&gt;%\n    # summarise(across(all_of(vars), ~ list(chisq.test(table(Clusters, .x)))))%&gt;% \n  pivot_longer(cols = everything(), names_to = \"Variables\", values_to = \"test\") %&gt;% \n  rowwise()%&gt;% \n  mutate(p.value = test$p.value) %&gt;% \n   left_join(\n    subject_info %&gt;% \n      summarise(across(all_of(vars), ~sum(!is.na(.x)))) %&gt;% \n      pivot_longer(cols = everything(), names_to = \"Variables\", values_to = \"n\") \n    ) %&gt;% \n  select(-test) %&gt;%\n  custom_flextable(\"Comparison of socioeconomic status variables between clusters (Fisher's exact test)\") %&gt;% \n  bold(j = ~p.value, i = ~p.value &lt; .05) \n\n\nVariablesp.valuenSex0.537104",
    "crumbs": [
      "Index",
      "Main Analyses"
    ]
  },
  {
    "objectID": "ensemble_clustering_results.html#table-s2.-comparison-of-temperamental-and-contextual-variables-between-clusters-kruskal-walliss-test",
    "href": "ensemble_clustering_results.html#table-s2.-comparison-of-temperamental-and-contextual-variables-between-clusters-kruskal-walliss-test",
    "title": "Main Analyses",
    "section": "3.2. Table S2. Comparison of temperamental and contextual variables between clusters (Kruskal Wallis’s test)",
    "text": "3.2. Table S2. Comparison of temperamental and contextual variables between clusters (Kruskal Wallis’s test)\n\n\nCode\nvars = c(\"Age\", \"NES\", \"Surgency\", \"Effortful control\", \"Negative affect\")\n\ndatos.summarised.info =  subject_info %&gt;%\n  select(Clusters, all_of(vars)) %&gt;%\n  pivot_longer(-Clusters,names_to = \"Variables\", values_to = \"value\") %&gt;%\n  \n  group_by(Clusters, Variables) %&gt;% \n  summarise(Mean = mean(value, na.rm = T),\n            SD = sd(value, na.rm = T),\n            n = sum(!is.na(value))\n            ) %&gt;% \n  ungroup() %&gt;% \n  select(Variables, Clusters, everything()) %&gt;% \n  arrange(Variables)\n\n\nkruskal.info = subject_info %&gt;%\n  summarise(across(all_of(vars), ~ list(kruskal.test(.x, Clusters))))%&gt;% \n  pivot_longer(cols = everything(), names_to = \"Variables\", values_to = \"test\") %&gt;% \n  rowwise()%&gt;% \n  mutate(statistic = test$statistic,p.value = test$p.value) %&gt;% \n  select(-test)\n\n\n\ndatos.summarised.info %&gt;% \n  left_join(kruskal.info, by = \"Variables\") %&gt;% \n  mutate(Variables = factor(Variables, levels = vars)) %&gt;%\n  arrange(Variables) %&gt;% \n  custom_flextable(\"Table S2. Comparison of individual and contextual variables between clusters (Kurskal Wallis's test)\") %&gt;%\n  bold(j = 7,~ `p.value` &lt; .05) %&gt;%\n  mk_par(j = 7,i = ~`p.value` &lt; .001, value = as_paragraph(\"&lt;.001\")) %&gt;%\n  merge_v(j = c(1,6:7)) %&gt;%\n  valign(valign = \"top\")\n\n\nVariablesClustersMeanSDnstatisticp.valueAgeCluster 15.3380.366361.4060.495Cluster 25.3910.34420Cluster 35.2870.28639NESCluster 128.8614.740361.7220.423Cluster 229.6193.94321Cluster 328.2824.95239SurgencyCluster 14.7050.769366.9900.03Cluster 24.3210.44320Cluster 34.4730.74539Effortful controlCluster 15.3080.587360.8990.638Cluster 25.3690.59620Cluster 35.1950.63539Negative affectCluster 14.8460.809360.4190.811Cluster 24.8370.61020Cluster 34.7730.76239\n\n\n\n\nCode\npairwise.wilcox.test(subject_info$Surgency, subject_info$Clusters, p.adjust.method = \"holm\") %&gt;% \n  broom::tidy() %&gt;%\n        mutate(contrasts = paste(group2, \"vs.\", group1)) %&gt;%\n        select(contrasts, p.value) %&gt;%\n        pivot_wider(names_from = contrasts, values_from = p.value) %&gt;% \n  mutate(Variable = c(\"Surgency\")) %&gt;% \n  select(Variable, everything()) %&gt;% \n\n\n  custom_flextable(\"Pairwise comparisons for clustering result\") %&gt;% \n  bold(j = 2,~ `Cluster 1 vs. Cluster 2` &lt; .05) %&gt;% \n  bold(j = 3,~ `Cluster 1 vs. Cluster 3` &lt; .05)%&gt;% \n  bold(j = 4,~ `Cluster 2 vs. Cluster 3` &lt; .05) %&gt;% \n  mk_par(j = 2,i = ~`Cluster 1 vs. Cluster 2` &lt; .001, value = as_paragraph(\"&lt;.001\")) %&gt;%\n  mk_par(j = 3,i = ~`Cluster 1 vs. Cluster 3` &lt; .001, value = as_paragraph(\"&lt;.001\")) %&gt;%\n  mk_par(j = 4,i = ~`Cluster 2 vs. Cluster 3` &lt; .001, value = as_paragraph(\"&lt;.001\")) %&gt;%\n  merge_v(j = 1:2) %&gt;% \n  valign(valign = \"top\")\n\n\nVariableCluster 1 vs. Cluster 2Cluster 1 vs. Cluster 3Cluster 2 vs. Cluster 3Surgency0.0260.1490.432",
    "crumbs": [
      "Index",
      "Main Analyses"
    ]
  },
  {
    "objectID": "pre_cluster_analysis.html",
    "href": "pre_cluster_analysis.html",
    "title": "Pre-clustering analyses",
    "section": "",
    "text": "Code\nrm(list=ls())\nset.seed(123)\n\nlibrary(tidyverse)\nlibrary(diceR)\nlibrary(factoextra)\nlibrary(FactoMineR)\nlibrary(flextable)\nlibrary(clusterability)\nsource(\"../helper/helper_tables.R\")\nsource(\"../helper/helper_functons.R\")",
    "crumbs": [
      "Index",
      "Supplementary materials",
      "Pre-clustering analyses"
    ]
  },
  {
    "objectID": "ensemble_clustering_results.html",
    "href": "ensemble_clustering_results.html",
    "title": "Main Analyses",
    "section": "",
    "text": "Code\nrm(list = ls())\nunlink(\"../Tables/*\")\nunlink(\"../Figures/*\")\n\n# set.seed(123)\nlibrary(tidyverse)\nlibrary(diceR)\nlibrary(flextable)\nlibrary(rstatix)\nlibrary(ggpubr)\nsource(\"../helper/helper_tables.R\")\nsource(\"../helper/helper_functons.R\")\n\n\n\n\nCode\n# Pre-processed data with subject ids\ndatos.reducidos = read.csv(\"../data/datos_reducidos.csv\")\n# Pre-processed data without subject ids\ndatos = read.csv(\"../data/datos_normalizados.csv\")\n# Subject info\nsubject_info &lt;- read.csv(\"../data/subject_information_PICT2014.csv\", check.names = F)",
    "crumbs": [
      "Index",
      "Main Analyses"
    ]
  },
  {
    "objectID": "ensemble_clustering_results.html#packages-functions-and-data",
    "href": "ensemble_clustering_results.html#packages-functions-and-data",
    "title": "Main Analyses",
    "section": "",
    "text": "Code\nrm(list = ls())\nunlink(\"../Tables/*\")\nunlink(\"../Figures/*\")\n\n# set.seed(123)\nlibrary(tidyverse)\nlibrary(diceR)\nlibrary(flextable)\nlibrary(rstatix)\nlibrary(ggpubr)\nsource(\"../helper/helper_tables.R\")\nsource(\"../helper/helper_functons.R\")\n\n\n\n\nCode\n# Pre-processed data with subject ids\ndatos.reducidos = read.csv(\"../data/datos_reducidos.csv\")\n# Pre-processed data without subject ids\ndatos = read.csv(\"../data/datos_normalizados.csv\")\n# Subject info\nsubject_info &lt;- read.csv(\"../data/subject_information_PICT2014.csv\", check.names = F)",
    "crumbs": [
      "Index",
      "Main Analyses"
    ]
  }
]