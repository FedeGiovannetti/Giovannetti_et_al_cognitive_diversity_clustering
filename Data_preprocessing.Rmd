---
title: "Data Pre-processing"
subtitle: "Variable selection and normalization"
output: html_document
---

The aim of the present code is to reduce the number of variables included for each task in order to avoid redundancy and multicolinearity. Criteria for variable exclusion are high correlation levels (Pearson's r above .7), and high number of missing data.

After variable exclusion, incomplete cases are removed and variables are scaled to z values.

```{r, message= F}

rm(list=ls())
library(tidyverse)
source("../helper/helper_tables.R")


base_general <- read.csv("../data/PICT_2014_PRE_filtered.csv")

```


## 1. Variable exclusion

In the first place, we will list all the available variables for each task.

```{r}

variables = colnames(base_general)[-c(1:2)]


# Extraer nombre de la tarea
task <- sub("_.*", "", variables)
task[!task %in% c("ANT", "CORSI", "TOL", "KBIT")] <- "Other"

# Remover el prefijo de tarea (ej: "ANT_") del nombre de variable
clean_name <- sub("^(ANT|CORSI|TOL|KBIT)_", "", variables)
clean_name <- gsub("_", " ", clean_name)

# Crear tabla final
table_vars <- data.frame(Task = task, Variable = clean_name) %>% 
  group_by(Task) %>% 
 summarise(n = n(),
           Variables = paste(Variable, collapse = ", "))

table_vars %>% 
  custom_flextable("Initial variables")






```


### 1.1. Checking variables with missing values

Variables such as RT in incorrect TOL and ANT trials seem to show a high amount of missing values

```{r}

base_general %>% 
  mutate(across(everything(), is.na)) %>% 
  
  mutate(across(everything(), as.numeric)) %>% 
  summarise(across(everything(), sum)) %>% 
  pivot_longer(everything(), names_to = "variables",
               values_to = "perdidos") %>% 
  arrange(desc(perdidos))

```


## 1.2. Checking variables with high correlation values

Correlation analyses between all included variables were run and all statistically significant (p \< 0.05) correlations with r \> 0.7 were selected.

```{r}

correlaciones = base_general %>% 
  select(-username,-Year) %>% 
  psych::corr.test(.)


p.correlaciones = correlaciones$p %>% 
  as.data.frame() %>% 
  rownames_to_column("variable_1") %>% 
pivot_longer(cols = -variable_1,
             names_to = "variable_2",
             values_to = "p.value") %>% 
  mutate(p.value = round(p.value, digits = 5))


r.correlaciones = correlaciones$r %>% 
    as.data.frame() %>% 
  rownames_to_column("variable_1") %>% 
pivot_longer(cols = -variable_1,
             names_to = "variable_2",
             values_to = "r")

correlaciones.df = left_join(r.correlaciones, p.correlaciones, by = c("variable_1", "variable_2"))


Correlaciones_tareas <- function(tarea, valor_r, valor_p){
  
  correlaciones.df %>% 
  filter(duplicated(r)) %>% 
  filter(r != 1) %>% 
  filter(r > valor_r) %>%
  filter(p.value < valor_p) %>%
  filter(grepl(tarea, variable_1)) %>% 
  filter(grepl(tarea, variable_2))
  
}

Correlaciones_tareas("ANT", 0.7, 0.05)
Correlaciones_tareas("CORSI", 0.7, 0.05)
Correlaciones_tareas("TOL", 0.7, 0.05)
Correlaciones_tareas("KBIT", 0.7, 0.05)

```

## 1.3. Selecting variables  

With the selection criteria in mind, determined variables were selected for each task

```{r}

variables = c(
  
  # ANT
  
  "ANT_omitted_trials_amount_congruent",
  "ANT_omitted_trials_amount_incongruent",
  "ANT_correct_trials_amount_congruent",
  "ANT_correct_trials_amount_incongruent",
  "ANT_median_rt_correct_congruent",
  "ANT_median_rt_correct_incongruent",
  "ANT_rt_ejecutiva",
  "ANT_rt_orientacion",
  "ANT_rt_alerta",
  
  # CORSI
  
  "CORSI_correct_trials_amount",
  "CORSI_rt_median_correct",
  "CORSI_rt_median_incorrect",
  
  # TOL
  
  "TOL_correct_trials_amount",
  "TOL_rt_planning_median_correct",
  # "TOL_rt_planning_median_incorrect",
  
  # KBIT
  
  "KBIT_correct_trials_amount"
  
  )
  
  
```

## 2. Data normalization

In order to implement a correct clusterization, all cases with missing values were excluded, and variables were converted to z values.
```{r}


datos.reducidos = base_general %>% 
  select(all_of(c("username",variables))) %>% 
  # select(-starts_with(c("STROOP"))) %>%
  na.omit

write.csv(datos.reducidos, "../data/datos_reducidos.csv", row.names = F) # Includes non scaled data

datos_normalizados <- datos.reducidos %>% 
  select(-username) %>%
  scale() %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric), scale)) %>%
  mutate(across((contains("omitted")), ~ . * -1)) ## Variables related to omitted trials were
                                                  ## inverted so positive refer to "better" performaces.
  

write.csv(datos_normalizados, "../data/datos_normalizados.csv", row.names = F) # Includes scaled data

```
